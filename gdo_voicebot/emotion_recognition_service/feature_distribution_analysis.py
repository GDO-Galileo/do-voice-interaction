
import csv
import sys
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

sys.path.append(".")
from helper import get_pathlist_from_dir

# Define folder that contains all of the clip folders
# We use processed label as each CSV file contains both valence and arousal
LABEL_DIR = './MuSe-CAR/label/processed'

# Copied parition generated by partition_generator.py
TRAIN_FILES = ['23', '24', '25', '26', '27', '28', '29', '30', '31', '34', '35', '36', '37', '39', '40', '42', '43', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '122', '125', '155', '157', '159', '160', '162', '163', '165', '166', '168', '169', '171', '173', '175', '177', '178', '179', '180', '181', '183', '184', '186', '187', '188', '189', '190', '191', '192', '194', '194', '196', '198', '198', '199', '199', '201', '202', '204', '205', '207', '208', '210', '210', '211', '214', '219', '222', '225', '230', '233', '236', '240', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '261', '262', '263', '264', '266', '267', '268', '269', '270', '271', '272', '273', '274']
DEVEL_FILES = ['293', '220', '279', '229', '280', '300', '287', '275', '17', '20', '301', '286', '276', '15', '18', '289', '239', '16', '243', '217', '215', '238', '244', '241', '297', '242', '231', '234', '291', '278', '38']
TEST_FILES = ['21', '19', '302', '290', '285', '298', '303', '292', '232', '213', '221', '282', '227', '235', '288', '284', '212', '296', '283', '228', '223', '224', '22', '226', '218', '295', '237', '281', '216', '277', '294']

#DEVEL_SAMPLE_FILES = ['15_2', '15_24', '15_3', '15_35', '15_36', '15_8', '16_12', '16_7', '17_12', '17_25', '17_26', '18_16', '18_22', '18_28', '20_13', '20_15', '20_19', '20_3', '215_14', '215_15', '215_22', '215_41', '215_44', '217_18', '217_40', '217_8', '220_1', '220_26', '220_35', '229_12', '229_5', '229_6', '231_10', '231_31', '234_26', '234_30', '238_18', '238_19', '238_31', '239_24', '239_27', '241_7', '241_9', '242_15', '243_16', '243_2', '244_4', '244_8', '275_12', '275_3', '275_4', '276_24', '276_27', '276_29', '278_4', '279_25', '279_33', '279_34', '279_41', '279_47', '279_50', '279_51', '279_52', '280_17', '280_20', '280_21', '280_23', '280_33', '280_46', '280_52', '280_62', '286_104', '286_11', '286_12', '286_20', '286_22', '286_26', '286_34', '286_40', '286_50', '286_53', '286_55', '286_65', '286_81', '286_87', '286_98', '287_1', '287_11', '287_16', '287_17', '289_15', '289_21', '291_17', '291_18', '291_26', '291_28', '291_33', '291_37', '291_41', '291_59', '291_61', '293_12', '293_22', '293_23', '293_27', '297_17', '297_22', '300_1', '300_10', '300_20', '301_13', '301_15', '301_26', '301_9', '38_28', '38_30', '38_32']

def get_features():
    train_arousal, train_valence = [], []
    devel_arousal, devel_valence = [], []
    test_arousal, test_valence = [], []
    n_train_frames = 0
    n_devel_frames = 0
    n_test_frames = 0

    folders = get_pathlist_from_dir(LABEL_DIR)
    n_clips_to_go = 227 # 303 minus 64 as there initially were 303 clips and then I mannually removed 64 as they did not have labels (test set) minus 12 clips without any transcript entry
    for path in folders:
        clipname = path.rsplit('/')[-1] # i.e. folder name e.g. 201
        #print('Getting features from clip ' + clipname) 

        if clipname in TRAIN_FILES:
            set = 'train'
        elif clipname in DEVEL_FILES:
            set = 'devel'
        elif clipname in TEST_FILES:
            set = 'test'
        else:
            print('This folder does not belong to any set, please double-check the hard coded parition')
            exit(-1)

        segments = get_pathlist_from_dir(LABEL_DIR + '/' + clipname)

        for segment in segments:
            segmentname = segment.rsplit('/')[-1][:-4] # i.e. segment name e.g. 201_1
            #print('Working on ' + segmentname)
            
            with open(segment, 'r') as tmp:
                    for row in csv.reader(tmp, delimiter=";"):
                        _, a, v = row
                        if set == 'train':
                            train_arousal.append(float(a))
                            train_valence.append(float(v))
                            n_train_frames += 1
                        elif set == 'devel':
                            devel_arousal.append(float(a))
                            devel_valence.append(float(v))
                            n_devel_frames += 1
                        elif set == 'test':
                            test_arousal.append(float(a))
                            test_valence.append(float(v))
                            n_test_frames += 1
        
        n_clips_to_go -= 1
        print(str(n_clips_to_go) + ' clips to go')
    
    n_total_frames = n_train_frames + n_devel_frames + n_test_frames
    print('*************** Data set size ****************')
    print('total number of frames = ' + str(n_total_frames))
    print('number of frames in train set = ' + str(n_train_frames) + ' which is ' + str(round((n_train_frames/n_total_frames*100),2)) + '% of the whole')
    print('number of frames in devel set = ' + str(n_devel_frames) + ' which is ' + str(round((n_devel_frames/n_total_frames*100),2)) + '% of the whole')
    print('number of frames in test set = ' + str(n_test_frames) + ' which is ' + str(round((n_test_frames/n_total_frames*100),2)) + '% of the whole')
    
    return train_arousal, train_valence, devel_arousal, devel_valence, test_arousal, test_valence

'''
def devel_sample():
    DEVEL_SAMPLE_FILES = []
    for clipname in DEVEL_FILES:
        segments = get_pathlist_from_dir(LABEL_DIR + '/' + clipname)
        for segment in segments:
            DEVEL_SAMPLE_FILES.append(segment.rsplit('/')[-1].rsplit('.')[0])
    print(DEVEL_SAMPLE_FILES)

    DEVEL_SAMPLE_FILES = np.array(DEVEL_SAMPLE_FILES) # convert list to np array
    np.random.shuffle(DEVEL_SAMPLE_FILES) # shuffle
    DEVEL_SAMPLE_FILES = DEVEL_SAMPLE_FILES[:len(DEVEL_SAMPLE_FILES)//10] # only take some of the whole devel set
    DEVEL_SAMPLE_FILES = DEVEL_SAMPLE_FILES.tolist()

    print('Analysing development sample (for plotting evaluation - mini devel)')
    print(sorted(DEVEL_SAMPLE_FILES))
    devel_sample_arousal = []
    devel_sample_valence = []
    devel_sample_folder = get_pathlist_from_dir('./tfrecords/data/devel_sample')
    n_frames = 0
    
    for segmentname in DEVEL_SAMPLE_FILES:
        clip = segmentname.rsplit('_')[0]
        path = LABEL_DIR + '/' + clip + '/' + segmentname + '.csv'
        with open(path, 'r') as tmp:
            for row in csv.reader(tmp, delimiter=";"):
                _, a, v = row
                devel_sample_arousal.append(float(a))
                devel_sample_valence.append(float(v))
                n_frames += 1
    return devel_sample_arousal, devel_sample_valence, n_frames
'''

if __name__ == '__main__':
    train_arousal, train_valence, devel_arousal, devel_valence, test_arousal, test_valence = get_features()
    
    print('*************** Min and Max ****************')

    print('min(train_arousal) = ' + str(min(train_arousal)))
    print('max(train_arousal) = ' + str(max(train_arousal)))

    print('min(train_valence) = ' + str(min(train_valence)))
    print('max(train_valence) = ' + str(max(train_valence)))

    print('min(devel_arousal) = ' + str(min(devel_arousal)))
    print('max(devel_arousal) = ' + str(max(devel_arousal)))

    print('min(devel_valence) = ' + str(min(devel_valence)))
    print('max(devel_valence) = ' + str(max(devel_valence)))

    print('min(test_arousal) = ' + str(min(test_arousal)))
    print('max(test_arousal) = ' + str(max(test_arousal)))

    print('min(test_valence) = ' + str(min(test_valence)))
    print('max(test_valence) = ' + str(max(test_valence)))

    plot1 = plt.figure(1)
    x_multi = np.array([train_arousal, devel_arousal, test_arousal])
    plt.hist(x_multi, 10, histtype='bar', label=['train_arousal', 'devel_arousal', 'test_arousal'])
    plt.title('Arousal for train, devel and test')
    plt.legend(prop={'size': 10})
    plt.xlabel("Value")
    plt.ylabel("Count")
    plt.xlim(0, 1)
    plt.xticks(np.arange(-1, 1, step=0.2))

    plot2 = plt.figure(2)
    x_multi = np.array([train_valence, devel_valence, test_valence])
    plt.hist(x_multi, 10, histtype='bar', label=['train_valence', 'devel_valence', 'test_valence'])
    plt.title('Valence for train, devel and test')
    plt.legend(prop={'size': 10})
    plt.xlabel("Value")
    plt.ylabel("Count")
    plt.xlim(0, 1)
    plt.xticks(np.arange(-1, 1, step=0.2))

    plot3 = plt.figure(3)
    x_multi = np.array([train_arousal, devel_arousal, test_arousal])
    plt.hist(x_multi, 10, density=True, histtype='bar', label=['train_arousal', 'devel_arousal', 'test_arousal'])
    plt.title('Arousal for train, devel and test (Normalised)')
    plt.legend(prop={'size': 10})
    plt.xlabel("Value")
    plt.ylabel("Count")
    plt.xlim(0, 1)
    plt.xticks(np.arange(-1, 1, step=0.2))

    plot4 = plt.figure(4)
    x_multi = np.array([train_valence, devel_valence, test_valence])
    plt.hist(x_multi, 10, density=True, histtype='bar', label=['train_valence', 'devel_valence', 'test_valence'])
    plt.title('Valence for train, devel and test (Normalised)')
    plt.legend(prop={'size': 10})
    plt.xlabel("Value")
    plt.ylabel("Count")
    plt.xlim(0, 1)
    plt.xticks(np.arange(-1, 1, step=0.2))
    '''
    devel_sample_arousal, devel_sample_valence, n_frames = devel_sample()

    plot5 = plt.figure(5)
    x_multi = np.array([devel_arousal, devel_sample_arousal])
    plt.hist(x_multi, 10, density=True, histtype='bar', label=['devel_arousal', 'devel_sample_arousal'])
    plt.title('Arousal for Devel and Devel Sample (Normalised)')
    plt.legend(prop={'size': 10})
    plt.xlabel("Value")
    plt.ylabel("Count")
    plt.xlim(0, 1)
    plt.xticks(np.arange(-1, 1, step=0.2))

    plot6 = plt.figure(6)
    x_multi = np.array([devel_valence, devel_sample_valence])
    plt.hist(x_multi, 10, density=True, histtype='bar', label=['devel_valence', 'devel_sample_valence'])
    plt.title('Valence for Devel and Devel Sample (Normalised)')
    plt.legend(prop={'size': 10})
    plt.xlabel("Value")
    plt.ylabel("Count")
    plt.xlim(0, 1)
    plt.xticks(np.arange(-1, 1, step=0.2))
    '''
    plt.show()
